{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import utils as utils\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_PATH = 'data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:  8000\n",
      "Test set size:  2000\n",
      "Sample tokenized review:  ['I', 'have', 'used', '``', 'vrbo', \"''\", 'and', 'home', 'away', 'websites', 'for', 'a', 'longtime', '.', 'This', 'is', 'the', 'worst', 'experience', 'I', 'have', 'ever', 'had', 'with', 'a', 'site', '.', 'My', 'friends', 'and', 'I', 'were', 'trying', 'to', 'book', 'a', 'place', 'for', 'the', 'Essence', 'Festival', 'in', 'July', '.', 'We', 'knew', 'how', 'the', 'housing', 'would', 'be', 'an', 'issue', 'so', 'we', 'started', 'looking', 'for', 'a', 'place', 'to', 'stay', 'at', 'the', 'end', 'of', 'Feb.', 'We', 'saw', 'the', 'French', 'Quarter', 'Suites', 'offered', 'Town', 'homes', ',', 'they', 'looked', 'nice', ',', 'so', 'we', 'began', 'to', 'inquire', '.', 'The', 'process', 'is', 'usually', 'pretty', 'easy', 'but', 'working', 'with', 'Ms.', 'Leslie', 'was', 'not', '.', 'When', 'asking', 'questions', 'about', 'a', '5br', 'town', 'home', 'she', 'would', 'often', 'skirt', 'the', 'questions', 'and', 'not', 'give', 'direct', 'answers', '.', 'She', 'raised', 'the', 'prices', 'on', 'our', 'stay', ',', 'without', 'our', 'knowledge', 'and', 'refused', 'to', 'breakdown', 'the', 'price', 'of', 'our', 'payment', '.', 'The', 'pay', 'for', 'parking', 'was', 'never', 'mentioned', ',', 'and', 'the', 'we', 'had', 'to', 'inquire', 'why', 'the', 'invoice', 'stated', 'the', 'town', 'home', 'was', 'a', 'one', 'room', 'annex', 'NOT', 'a', '5', 'bedroom', 'town', 'house', '.', 'The', 'Frech', 'Quarter', 'Suites', 'Hotel', 'website', 'and', 'business', 'are', 'misleading', 'and', 'dishonest', '.']\n",
      "Sample rating:  1\n"
     ]
    }
   ],
   "source": [
    "train_tups, test_tups = utils.split_data(utils.generate_tuples_from_file(DATA_FILE_PATH, num_samples=10000), test_size=0.2)\n",
    "\n",
    "print('Training set size: ', len(train_tups[0]))\n",
    "print('Test set size: ', len(test_tups[0]))\n",
    "print('Sample tokenized review: ', train_tups[0][0])\n",
    "print('Sample rating: ', train_tups[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22163\n"
     ]
    }
   ],
   "source": [
    "X_train_text = [' '.join(words) for words in train_tups[0]]\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train_text)\n",
    "\n",
    "print(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vectorized, train_tups[1] )\n",
    "\n",
    "test_review1 = [\"the food was terrible\"]\n",
    "test_review2 = [\"I loved my meal\"]\n",
    "\n",
    "vectorized_test_review1 = vectorizer.transform(test_review1)\n",
    "vectorized_test_review2 = vectorizer.transform(test_review2)\n",
    "\n",
    "prediction1 = model.predict(vectorized_test_review1)\n",
    "prediction2 = model.predict(vectorized_test_review2)\n",
    "\n",
    "print(prediction1)\n",
    "print(prediction2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
