{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import utils as utils\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_PATH = 'data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:  8000\n",
      "Test set size:  2000\n",
      "Sample tokenized review:  ['I', 'was', 'just', 'visiting', 'St', 'Louis/Clayton', 'for', 'a', 'business', 'trip', '.', 'I', 'was', 'referred', 'to', 'Sauce', 'on', 'the', 'Side', 'by', 'a', 'colleague', '.', 'It', 'is', 'amazing', 'to', 'say', 'the', 'least', '.', 'The', 'food', 'is', 'fresh', 'and', 'creative', '.', 'I', 'ate', 'there', '3', 'times', 'that', 'week', '!', 'Super', 'friendly', 'staff', '.', 'They', 'even', 'gave', 'me', 'the', 'low', 'down', 'on', 'the', 'local', 'beers', '!', 'Love', '4HandsBrewing', 'by', 'the', 'way', '!']\n",
      "Sample rating:  5\n"
     ]
    }
   ],
   "source": [
    "train_tups, test_tups = utils.split_data(utils.generate_tuples_from_file(DATA_FILE_PATH, num_samples=10000), test_size=0.2)\n",
    "\n",
    "print('Training set size: ', len(train_tups[0]))\n",
    "print('Test set size: ', len(test_tups[0]))\n",
    "print('Sample tokenized review: ', train_tups[0][0])\n",
    "print('Sample rating: ', train_tups[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22114\n"
     ]
    }
   ],
   "source": [
    "X_train_text = [' '.join(words) for words in train_tups[0]]\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train_text)\n",
    "\n",
    "print(len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 1. 4. ... 3. 2. 5.]\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Using the provided dev set, evaluate your model with precision, recall, and f1 score as well as accuracy\n",
    "# You may use nltk's implemented `precision`, `recall`, `f_measure`, and `accuracy` functions\n",
    "# (make sure to look at the documentation for these functions!)\n",
    "# you will be creating a similar graph for logistic regression and neural nets, so make sure\n",
    "# you use functions wisely so that you do not have excessive repeated code\n",
    "# write any helper functions you need in sentiment_utils.py (functions that you'll use in your other notebooks as well)\n",
    "\n",
    "# create a graph of your classifier's performance on the dev set as a function of the amount of training data\n",
    "# the x-axis should be the amount of training data (as a percentage of the total training data)\n",
    "# the y-axis should be the performance of the classifier on the dev set\n",
    "# the graph should have 4 lines, one for each of precision, recall, f1, and accuracy\n",
    "# the graph should have a legend, title, and axis label\n",
    "\n",
    "# USING COUNT VECTORIZER\n",
    "\n",
    "train_sizes = []\n",
    "accuracies = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "losses = []\n",
    "precisions = []\n",
    "\n",
    "total_samples = len(train_tups[0])\n",
    "step_size = total_samples // 10\n",
    "\n",
    "for i in range(1, 11):\n",
    "    num_samples = step_size * i\n",
    "    partial_train_data = train_tups[0][:num_samples]\n",
    "    partial_train_labels = train_tups[1][:num_samples]\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_text = [' '.join(words) for words in train_tups[0][:num_samples]] \n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train_text).toarray()\n",
    "    y_train = np.array(train_tups[1][:num_samples]).astype(np.float32)\n",
    "    input_dim = X_train_vectorized.shape[1]\n",
    "\n",
    "    model  = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "    X_dev_text = [' '.join(words) for words in test_tups[0]]\n",
    "    X_dev_vectorized = vectorizer.transform(X_dev_text).toarray().astype(np.float32)\n",
    "    y_dev = np.array(test_tups[1]).astype(np.float32)\n",
    "\n",
    "    X_dev_vectorized = np.pad(X_dev_vectorized, ((0, 0), (0, X_train_vectorized.shape[1] - X_dev_vectorized.shape[1])), 'constant')\n",
    "    lr_preds = model.predict(X_dev_vectorized)\n",
    "    print(lr_preds)\n",
    "    print(len(lr_preds))\n",
    "    break\n",
    "#     accuracy = accuracy_score(lr_preds, y_dev )\n",
    "#     recall = recall_score(lr_preds, y_dev )\n",
    "#     cur_f1_score = f1_score(lr_preds, y_dev )\n",
    "#     precision = precision_score(lr_preds, y_dev )\n",
    "\n",
    "#     train_sizes.append(i*10)\n",
    "#     accuracies.append(accuracy)\n",
    "#     f1_scores.append(cur_f1_score)\n",
    "#     recalls.append(recall)\n",
    "#     precisions.append(precision)\n",
    "\n",
    "\n",
    "\n",
    "# # Plotting the graph\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(train_sizes, precisions, label='Precision')\n",
    "# plt.plot(train_sizes, recalls, label='Recall')\n",
    "# plt.plot(train_sizes, f1_scores, label='F1 Score')\n",
    "# plt.plot(train_sizes, accuracies, label='Accuracy')\n",
    "\n",
    "# plt.title(\"Logistic Regression Performance vs. Training Data Size\")\n",
    "# plt.xlabel(\"Percentage of Training Data\")\n",
    "# plt.ylabel(\"Performance\")\n",
    "# plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
